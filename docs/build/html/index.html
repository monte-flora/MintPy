

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>PyMint Documentation &mdash; PyMint v0.0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/favicon.png"/>
  
  
  

  

  
  
    

  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/audeering.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    
  

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          <a href="#">
          
            <img src="_static/images/audeering.svg" class="logo" alt="audEERING"/>
          
          
            <span> PyMint</span>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">PyMint Documentation</a></li>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#module-pymint.main.interpret_toolkit">Documentation</a><ul>
<li><a class="reference internal" href="#contribute">Contribute</a></li>
<li><a class="reference internal" href="#support">Support</a></li>
<li><a class="reference internal" href="#license">License</a></li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">PyMint</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>PyMint Documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://gitlab.audeering.com/monte-flora/py-mint/blob/master/docs/index.rst" class="fa fa-gitlab"> Edit on GitLab</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="pymint-documentation">
<h1>PyMint Documentation<a class="headerlink" href="#pymint-documentation" title="Permalink to this headline">¶</a></h1>
<p>PyMint (Python-based Model INTerpretations) is designed to be a user-friendly package for computing and plotting machine learning interpretation output in Python. Current computation includes partial dependence (PD), accumulated local effects (ALE), random forest-based feature contributions (treeinterpreter), single- and multiple-pass permutation importance, and Shapley Additive Explanations (SHAP). All of these methods are discussed at length in Christoph Molnar’s interpretable ML book (<a class="reference external" href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a>). Most calculations can be performed in parallel when multi-core processing is available. The primary feature of this package is the accompanying built-in plotting methods, which are desgined to be easy to use while producing publication-level quality figures.</p>
</section>
<section id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>pip install py-mint</p>
</section>
<section id="module-pymint.main.interpret_toolkit">
<span id="documentation"></span><h1>Documentation<a class="headerlink" href="#module-pymint.main.interpret_toolkit" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">pymint.main.interpret_toolkit.</span></code><code class="sig-name descname"><span class="pre">InterpretToolkit</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">estimators=None</span></em>, <em class="sig-param"><span class="pre">estimator_names=None</span></em>, <em class="sig-param"><span class="pre">X=Empty</span> <span class="pre">DataFrame</span> <span class="pre">Columns:</span> <span class="pre">[0]</span> <span class="pre">Index:</span> <span class="pre">[]</span></em>, <em class="sig-param"><span class="pre">y=array([]</span></em>, <em class="sig-param"><span class="pre">dtype=float64)</span></em>, <em class="sig-param"><span class="pre">estimator_output=None</span></em>, <em class="sig-param"><span class="pre">feature_names=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit" title="Permalink to this definition">¶</a></dt>
<dd><p>InterpretToolkit is the primary interface of PyMint. The modules contained within compute several
interpretable machine learning (IML) methods such as</p>
<p>Feature importance:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>permutation_importance</cite></p></li>
<li><p><cite>ale_variance</cite></p></li>
</ul>
</div></blockquote>
<p>Feature Attributions:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>ale</cite></p></li>
<li><p><cite>pd</cite></p></li>
<li><p><cite>ice</cite></p></li>
<li><p><cite>shap</cite></p></li>
<li><p><cite>local_contributions</cite></p></li>
</ul>
</div></blockquote>
<p>Feature Interactions:</p>
<blockquote>
<div><ul class="simple">
<li><p><cite>interaction_strength</cite></p></li>
<li><p><cite>ale_variance</cite></p></li>
<li><p><cite>perm_based_interaction</cite></p></li>
<li><p><cite>friedman_h_stat</cite></p></li>
<li><p><cite>main_effect_complexity</cite></p></li>
<li><p><cite>ale</cite></p></li>
<li><p><cite>pd</cite></p></li>
</ul>
</div></blockquote>
<p>Additionally, there are corresponding plotting modules for
each IML method, which are designed to produce publication-quality graphics.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>InterpretToolkit is designed to work with estimators that implement predict or predict_proba.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>InterpretToolkit is only designed to work with binary classification and regression problems.
In future versions of PyMint, we hope to be compatiable with multi-class classification.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimators</strong> (<em>model object</em><em>, </em><em>list of model objects</em>) – A fitted estimator object or list thereof implementing <cite>predict</cite> or
<cite>predict_proba</cite>.
Multioutput-multiclass classifiers are not supported.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list</em>) – Names of the estimators (for internal and plotting purposes)</p></li>
<li><p><strong>X</strong> (<em>{array-like</em><em> or </em><em>dataframe} of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training or validation data used to compute the IML methods.
If ndnumpy.array, must specify <cite>feature_names</cite></p></li>
<li><p><strong>y</strong> (<em>{list</em><em> or </em><em>numpy.array} of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – <dl class="simple">
<dt>The target values (class labels in classification, real numbers in</dt><dd><p>regression).</p>
</dd>
</dl>
</p></li>
<li><p><strong>estimator_output</strong> (<em>&quot;raw&quot;</em><em> or </em><em>&quot;probability&quot;</em>) – What output of the estimator should be explained. Determined internally by
InterpretToolkit. However, if using a classification model, the user
can set to “raw” for non-probabilistic output.</p></li>
<li><p><strong>feature_names</strong> (<em>array-like of shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em><em>, </em><em>dtype=str</em><em>, </em><em>default=None</em>) – Name of each feature; <cite>feature_names[i]</cite> holds the name of the feature
with index <cite>i</cite>. By default, the name of the feature corresponds to their numerical
index for NumPy array and their column name for pandas dataframe.
Feature names are only required if X is an ndnumpy.array, a it will be
converted to a pandas.DataFrame internally.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>AssertError</strong> – Number of estimator objects is not equal to the number of estimator names given!</p></li>
<li><p><strong>TypeError</strong> – y variable must be numpy array or pandas.DataFrame.</p></li>
<li><p><strong>Exception</strong> – Feature names must be specified if X is an numpy.array.</p></li>
<li><p><strong>ValueError</strong> – estimator_output is not an accepted option.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.ale">
<code class="sig-name descname"><span class="pre">ale</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.ale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the 1D or 2D centered accumulated local effects (ALE) <a class="footnote-reference brackets" href="#id3" id="id1">9</a> <a class="footnote-reference brackets" href="#id4" id="id2">10</a> If any features are categorical,
then set the type of those features as ‘category’ in the pandas.DataFrame. E.g.,
X = X.astype({‘urban’: ‘category’, ‘rural’:’category’})</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">9</a></span></dt>
<dd><p><a class="reference external" href="https://christophm.github.io/interpretable-ml-book/ale.html">https://christophm.github.io/interpretable-ml-book/ale.html</a></p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">10</a></span></dt>
<dd><p>Apley, D. W., and J. Zhu, 2016: Visualizing the Effects of Predictor Variables in</p>
</dd>
</dl>
<p>Black Box Supervised Learning Models. ArXiv.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>string</em><em> or </em><em>list of strings</em><em> or </em><em>'all'</em>) – Features to compute the PD for.  if ‘all’, the method will compute
the ALE for all features.</p></li>
<li><p><strong>n_bins</strong> (<em>integer</em><em> (</em><em>default=30</em><em>)</em>) – Number of bins used to compute the ALE for. Bins are decided based
on percentile intervals to ensure the same number of samples are in
each bin.</p></li>
<li><p><strong>n_jobs</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1</em><em>)</em>) – <ul>
<li><p>if integer, interpreted as the number of processors to use for multiprocessing</p></li>
<li><p>if float, interpreted as the fraction of proceesors to use for multiprocessing</p></li>
</ul>
</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1.0</em><em>)</em>) – <ul>
<li><p>if value between 0-1 interpreted as fraction of total X to use</p></li>
<li><p>if value &gt; 1, interpreted as the absolute number of random samples of X.</p></li>
</ul>
</p></li>
<li><p><strong>n_bootstrap</strong> (<em>integer</em><em> (</em><em>default=1; no bootstrapping</em><em>)</em>) – Number of bootstrap resamples for computing confidence intervals on the ALE curves.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – ALE result dataset</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.DataSet</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>Exception</strong> – Highly skewed data may not be divisable into n_bins given. In that case, calc_ale
    uses the max bins the data can be divided into. But a warning message is raised.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span> <span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Set the type for categorical features and InterpretToolkit with compute the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># categorical ALE.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;urban&#39;</span><span class="p">:</span> <span class="s1">&#39;category&#39;</span><span class="p">,</span> <span class="s1">&#39;rural&#39;</span><span class="p">:</span><span class="s1">&#39;category&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.ale_variance">
<code class="sig-name descname"><span class="pre">ale_variance</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.ale_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale_variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the standard deviation (std) of the ALE values for each
features in a dataset and then rank by the magnitude. A higher std(ALE) indicates a
greater expected contribution to an estimator’s prediction and is thus considered more important.
If <code class="docutils literal notranslate"><span class="pre">interaction=True</span></code>, then the method computes a similar method for the
2D ALE to measure the feature interaction strength.</p>
<p>This method is inspired by the feature importance and interaction
methods developed in Greenwell et al. (2018) <a class="footnote-reference brackets" href="#id6" id="id5">4</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ale</strong> (<em>xarray.Dataset</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale" title="pymint.main.interpret_toolkit.InterpretToolkit.ale"><code class="xref py py-func docutils literal notranslate"><span class="pre">ale()</span></code></a> for
<code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>features</strong> (<em>'all'</em><em>, </em><em>string</em><em>, </em><em>list of strings</em><em>, </em><em>list of 2-tuples</em>) – Features to compute the ALE variance for. If set to <code class="docutils literal notranslate"><span class="pre">'all'</span></code>, it is
computed for all features. If <code class="docutils literal notranslate"><span class="pre">interaction=True</span></code>, then features
must be a list of 2-tuples for computing the interaction between
the set of feature combinations.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute the ALE variance for.</p></li>
<li><p><strong>interaction</strong> (<em>boolean</em>) – <ul>
<li><p>If True, it computes the feature interaction strength</p></li>
<li><p>If False, compute the feature importance</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results_ds</strong> – ALE variance results. Includes both the rankings and scores.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.Dataset</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id5">4</a></span></dt>
<dd><p>Greenwell, B. M., B. C. Boehmke, and A. J. McCarthy, 2018:
A Simple and Effective estimator-Based Variable Importance Measure. Arxiv,.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute 1D ALE variance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale_var_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale_variance</span><span class="p">(</span><span class="n">ale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ale_var_results</span><span class="p">)</span>
<span class="go">&lt;xarray.Dataset&gt;</span>
<span class="go">Dimensions:    (n_bootstrap: 1, n_vars_ale_variance: 30)</span>
<span class="go">Dimensions without coordinates: n_bootstrap, n_vars_ale_variance</span>
<span class="go">Data variables:</span>
<span class="go">    ale_variance_rankings__Random Forest        (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="go">    ale_variance_scores__Random Forest          (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="go">    ale_variance_rankings__Gradient Boosting    (n_vars_ale_variance) &lt;U17 &#39;u...</span>
<span class="go">    ale_variance_scores__Gradient Boosting      (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="go">    ale_variance_rankings__Logistic Regression  (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="go">    ale_variance_scores__Logistic Regression    (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="go">Attribute:</span>
<span class="go">    estimator_output:  probability</span>
<span class="go">    estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="go">    n_multipass_vars:  5</span>
<span class="go">    method:            ale_variance</span>
<span class="go">    direction:         backward</span>
<span class="go">    evaluation_fn:     sigma_ale</span>
<span class="go">    dimension:         1D</span>
<span class="go">    features used:     [&#39;dllwave_flux&#39;, &#39;dwpt2m&#39;, &#39;fric_vel&#39;, &#39;gflux&#39;, &#39;high_...</span>
<span class="go">    estimator output:  probability</span>
<span class="go">    interaction:       False</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">#Typical, we only want to evaluate the feature interactions for</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the most important features</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sfc_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;temp2m&#39;</span><span class="p">,</span> <span class="s1">&#39;sfcT_hrs_bl_frez&#39;</span><span class="p">,</span> <span class="s1">&#39;tmp2m_hrs_bl_frez&#39;</span><span class="p">,</span>
<span class="gp">... </span>  <span class="s1">&#39;uplwav_flux&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create all possible combinations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars_2d</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">important_vars</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#For the 2D ALE variance to measure feature interaction strength</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale_2d</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">important_vars_2d</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>             <span class="n">subsample</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute 2D ALE variance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale_var_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale_variance</span><span class="p">(</span><span class="n">ale_2d</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">important_vars_2d</span><span class="p">,</span>
<span class="gp">... </span>                   <span class="n">interaction</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ale_var_results</span><span class="p">)</span>
<span class="go">&lt;xarray.Dataset&gt;</span>
<span class="go">Dimensions:   (n_bootstrap: 1, n_vars_ale_variance_interactions: 10)</span>
<span class="go">Dimensions without coordinates: n_bootstrap, n_vars_ale_variance_interactions</span>
<span class="go">Data variables:</span>
<span class="go">    ale_variance_interactions_rankings__Random Forest        (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="go">    ale_variance_interactions_scores__Random Forest          (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="go">    ale_variance_interactions_rankings__Gradient Boosting    (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="go">    ale_variance_interactions_scores__Gradient Boosting      (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="go">    ale_variance_interactions_rankings__Logistic Regression  (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="go">    ale_variance_interactions_scores__Logistic Regression    (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="go">Attribute:</span>
<span class="go">    estimator_output:  probability</span>
<span class="go">    estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="go">    n_multipass_vars:  5</span>
<span class="go">    method:            ale_variance</span>
<span class="go">    direction:         backward</span>
<span class="go">    evaluation_fn:     Interaction Importance</span>
<span class="go">    dimension:         2D</span>
<span class="go">    features used:     [(&#39;sfc_temp&#39;, &#39;temp2m&#39;), (&#39;sfc_temp&#39;, &#39;sfcT_hrs_bl_fre...</span>
<span class="go">    estimator output:  probability</span>
<span class="go">    interaction:       True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.friedman_h_stat">
<code class="sig-name descname"><span class="pre">friedman_h_stat</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pd_1d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pd_2d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.friedman_h_stat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.friedman_h_stat" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the second-order Friedman’s H-statistic for computing feature interactions <a class="footnote-reference brackets" href="#id10" id="id7">11</a> <a class="footnote-reference brackets" href="#id11" id="id8">12</a>.
Based on equation (44) from Friedman and Popescu (2008) <a class="footnote-reference brackets" href="#id11" id="id9">12</a>. Only computes the interaction strength
between two features. In future versions of PyMint he hope to include the first-order H-statistics
that measure the interaction between a single feature and the
remaining set of features.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id7">11</a></span></dt>
<dd><p><a class="reference external" href="https://christophm.github.io/interpretable-ml-book/interaction.html">https://christophm.github.io/interpretable-ml-book/interaction.html</a></p>
</dd>
<dt class="label" id="id11"><span class="brackets">12</span><span class="fn-backref">(<a href="#id8">1</a>,<a href="#id9">2</a>)</span></dt>
<dd><p>Friedman, J. H., and B. E. Popescu, 2008: Predictive learning via rule ensembles.
Ann Appl Statistics, 2, 916–954, <a class="reference external" href="https://doi.org/10.1214/07-aoas148">https://doi.org/10.1214/07-aoas148</a>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pd_1d</strong> (<em>xarray.Dataset</em>) – 1D partial dependence dataset. Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.pd" title="pymint.main.interpret_toolkit.InterpretToolkit.pd"><code class="xref py py-func docutils literal notranslate"><span class="pre">pd()</span></code></a> for <code class="docutils literal notranslate"><span class="pre">features</span></code></p></li>
<li><p><strong>pd_2d</strong> (<em>xarray.Dataset</em>) – 2D partial dependence dataset. Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.pd" title="pymint.main.interpret_toolkit.InterpretToolkit.pd"><code class="xref py py-func docutils literal notranslate"><span class="pre">pd()</span></code></a>, but 2-tuple combinations
of <code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>features</strong> (<em>list of 2-tuples of strings</em>) – The pairs of features to compute the feature interaction between.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em><em> (</em><em>default is None</em><em>)</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute the H-statistic for.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results_ds</strong> – The second-order Friedman H-statistic for all estimators.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.Dataset</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd_1d</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">pd</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd_2d</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">pd</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all_2d&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hstat</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">friedman_h_stat</span><span class="p">(</span><span class="n">pd_1d</span><span class="p">,</span> <span class="n">pd_2d</span><span class="p">,)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.get_important_vars">
<code class="sig-name descname"><span class="pre">get_important_vars</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perm_imp_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multipass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.get_important_vars"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.get_important_vars" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve the most important variables from permutation importance.
Can combine rankings from different estimators and only keep those variables that
occur in more than one estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>perm_imp_data</strong> (<em>xarray.Dataset</em>) – Permutation importance result dataset</p></li>
<li><p><strong>multipass</strong> (<em>boolean</em><em> (</em><em>defaults to True</em><em>)</em>) – if True, return the multipass rankings else returns the singlepass rankings</p></li>
<li><p><strong>n_vars</strong> (<em>integer</em><em> (</em><em>default=10</em><em>)</em>) – Number of variables to retrieve if multipass=True.</p></li>
<li><p><strong>combine</strong> (<em>boolean</em><em>  (</em><em>default=False</em><em>)</em>) – If combine=True, n_vars can be set such that you only include a certain amount of
top features from each estimator. E.g., n_vars=5 and combine=True means to combine
the top 5 features from each estimator into a single list.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<dl class="simple">
<dt>if combine=True</dt><dd><dl class="simple">
<dt>results<span class="classifier">list</span></dt><dd><p>List of top features from a different estimators.</p>
</dd>
</dl>
</dd>
<dt>if combine=False</dt><dd><dl class="simple">
<dt>results<span class="classifier">dict</span></dt><dd><p>keys are the estimator names and items are the
top features.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_imp_data</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">permutation_importance</span><span class="p">(</span>
<span class="gp">... </span>                      <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="s1">&#39;norm_aupdc&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">direction</span> <span class="o">=</span> <span class="s1">&#39;backward&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">get_important_vars</span><span class="p">(</span><span class="n">perm_imp_data</span><span class="p">,</span>
<span class="gp">... </span>       <span class="n">multipass</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># set combine=True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">get_important_vars</span><span class="p">(</span><span class="n">perm_imp_data</span><span class="p">,</span>
<span class="gp">... </span>       <span class="n">multipass</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.ice">
<code class="sig-name descname"><span class="pre">ice</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.ice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.ice" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the indiviudal conditional expectations (ICE) <a class="footnote-reference brackets" href="#id13" id="id12">7</a>.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id12">7</a></span></dt>
<dd><p><a class="reference external" href="https://christophm.github.io/interpretable-ml-book/ice.html">https://christophm.github.io/interpretable-ml-book/ice.html</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>string</em><em> or </em><em>list of strings</em><em> or </em><em>'all'</em>) – Features to compute the ICE for.  if ‘all’, the method will compute
the ICE for all features.</p></li>
<li><p><strong>n_bins</strong> (<em>integer</em><em> (</em><em>default=30</em><em>)</em>) – Number of bins used to compute the ICE for. Bins are decided based
on percentile intervals to ensure the same number of samples are in
each bin.</p></li>
<li><p><strong>n_jobs</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1</em><em>)</em>) – <ul>
<li><p>if integer, interpreted as the number of processors to use for multiprocessing</p></li>
<li><p>if float, interpreted as the fraction of proceesors to use for multiprocessing</p></li>
</ul>
</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1.0</em><em>)</em>) – <ul>
<li><p>if value between 0-1 interpreted as fraction of total X to use</p></li>
<li><p>if value &gt; 1, interpreted as the absolute number of random samples of X.</p></li>
</ul>
</p></li>
<li><p><strong>n_bootstrap</strong> (<em>integer</em><em> (</em><em>default=1; no bootstrapping</em><em>)</em>) – Number of bootstrap resamples for computing confidence intervals on the ICE curves.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – Main keys are the user-provided estimator names while the sub-key
are the features computed for. The items are data for the ICE curves. Also,
contains X data (feature values where the ICE curves were computed) for plotting.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.DataSet</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ice_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ice</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.interaction_strength">
<code class="sig-name descname"><span class="pre">interaction_strength</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.interaction_strength"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.interaction_strength" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the InterAction Strength (IAS) statistic from Molnar et al. (2019) <a class="footnote-reference brackets" href="#id16" id="id14">5</a>.
The IAS varies between 0-1 where values closer to 0 indicate no feature interaction
strength.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ale</strong> (<em>xarray.Dataset</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale" title="pymint.main.interpret_toolkit.InterpretToolkit.ale"><code class="xref py py-func docutils literal notranslate"><span class="pre">ale()</span></code></a>, but must be computed for all features</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em><em> (</em><em>default is None</em><em>)</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute the IAS for.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – <ul>
<li><p>subsample</p></li>
<li><p>n_bootstrap</p></li>
<li><p>estimator_output</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results_ds</strong> – Interaction strength result dataset</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.Dataset</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ias</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">interaction_strength</span><span class="p">(</span><span class="n">ale</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.load">
<code class="sig-name descname"><span class="pre">load</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fnames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dataset'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load results of a computation (permutation importance, calc_ale, calc_pd, etc)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fnames</strong> (<em>string</em><em> or </em><em>list of strings</em>) – File names of dataframes or datasets to load.</p></li>
<li><p><strong>dtype</strong> (<em>'dataset'</em><em> or </em><em>'dataframe'</em>) – Indicate whether you are loading a set of xarray.Datasets
or pandas.DataFrames</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – data for plotting purposes</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.DataSet or pandas.DataFrame</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;path/to/your/perm_imp_results&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_imp_data</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fnames</span><span class="o">=</span><span class="n">fname</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;dataset&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.local_contributions">
<code class="sig-name descname"><span class="pre">local_contributions</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'shap'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">performance_based</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.local_contributions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.local_contributions" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the individual feature contributions to a predicted outcome for
a series of examples either based on tree interpreter (only Tree-based methods)
or Shapley Additive Explanations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<code class="docutils literal notranslate"><span class="pre">'shap'</span></code> or <code class="docutils literal notranslate"><span class="pre">'tree_interpreter'</span></code>) – Can use SHAP or treeinterpreter to compute the feature contributions.
SHAP is estimator-agnostic while treeinterpreter can only be used on
select decision-tree based estimators in scikit-learn. SHAP will attempt
to first use the Tree-based explainer and if that fails, then the
Kernel-based explainer.</p></li>
<li><p><strong>background_dataset</strong> (<em>array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – A representative (often a K-means or random sample) subset of the
data used to train the ML estimator. Used for the background dataset
to compute the expected values for the SHAP calculations.
Only required for non-tree based estimators.</p></li>
<li><p><strong>performance_based</strong> (<em>boolean</em><em> (</em><em>default=False</em><em>)</em>) – If True, will average feature contributions over the best and worst
performing of the given X. The number of examples to average over
is given by n_samples</p></li>
<li><p><strong>n_samples</strong> (<em>interger</em><em> (</em><em>default=100</em><em>)</em>) – Number of samples to compute average over if performance_based = True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results_df</strong> – For each example, contributions from each feature plus the bias
The dataframe is nested by the estimator names and additional keys
if performance_based=True.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested pandas.DataFrame</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">shap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Only give the X you want contributions for.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, we are using a single example.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">single_example</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">single_example</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a background dataset; randomly sample 100 X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">background_dataset</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrib_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">local_contributions</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;shap&#39;</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">background_dataset</span><span class="o">=</span><span class="n">background_dataset</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># For the performance-based contributions,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># provide the full set of X and y values.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrib_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">local_contributions</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;shap&#39;</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">background_dataset</span><span class="o">=</span><span class="n">background_dataset</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">performance_based</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.main_effect_complexity">
<code class="sig-name descname"><span class="pre">main_effect_complexity</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_segments</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_error</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.main_effect_complexity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.main_effect_complexity" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Main Effect Complexity (MEC; Molnar et al. 2019) <a class="footnote-reference brackets" href="#id16" id="id15">5</a>.
MEC is the number of linear segements required to approximate
the first-order ALE curves averaged over all features.
The MEC is weighted-averged by the variance. Higher values indicate
a more complex estimator (less interpretable).</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id16"><span class="brackets">5</span><span class="fn-backref">(<a href="#id14">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Molnar, C., G. Casalicchio, and B. Bischl, 2019: Quantifying estimator Complexity via
Functional Decomposition for Better Post-Hoc Interpretability. ArXiv.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ale</strong> (<em>xarray.Dataset</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale" title="pymint.main.interpret_toolkit.InterpretToolkit.ale"><code class="xref py py-func docutils literal notranslate"><span class="pre">ale()</span></code></a>. Must be computed for all features in X.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute the MEC for.</p></li>
<li><p><strong>max_segments</strong> (<em>integer; default=10</em>) – Maximum number of linear segments used to approximate the main/first-order
effect of a feature. default is 10. Used to limit the computational runtime.</p></li>
<li><p><strong>approx_error</strong> (<em>float; default=0.05</em>) – The accepted error of the R squared between the piece-wise linear function
and the true ALE curve. If the R square is within the approx_error, then
no additional segments are added.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>mec_dict</strong> – mec_dict = {estimator_name0 : mec0, estimator_name1 : mec2, …, estimator_nameN : mecN,}</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute Main Effect Complexity (MEC)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mec_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">main_effect_complexity</span><span class="p">(</span><span class="n">ale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mes_ds</span><span class="p">)</span>
<span class="go">{&#39;Random Forest&#39;: 2.6792782503392756,</span>
<span class="go"> &#39;Gradient Boosting&#39;: 2.692392706080586,</span>
<span class="go"> &#39;Logistic Regression&#39;: 1.6338281469152958}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.pd">
<code class="sig-name descname"><span class="pre">pd</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.pd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.pd" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the 1D or 2D centered partial dependence (PD) <a class="footnote-reference brackets" href="#id18" id="id17">8</a>.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id18"><span class="brackets"><a class="fn-backref" href="#id17">8</a></span></dt>
<dd><p><a class="reference external" href="https://christophm.github.io/interpretable-ml-book/pdp.html">https://christophm.github.io/interpretable-ml-book/pdp.html</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>string</em><em> or </em><em>list of strings</em><em> or </em><em>'all'</em>) – Features to compute the PD for.  if ‘all’, the method will compute
the PD for all features.</p></li>
<li><p><strong>n_bins</strong> (<em>integer</em><em> (</em><em>default=30</em><em>)</em>) – Number of bins used to compute the PD for. Bins are decided based
on percentile intervals to ensure the same number of samples are in
each bin.</p></li>
<li><p><strong>n_jobs</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1</em><em>)</em>) – <ul>
<li><p>if integer, interpreted as the number of processors to use for multiprocessing</p></li>
<li><p>if float, interpreted as the fraction of proceesors to use for multiprocessing</p></li>
</ul>
</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1.0</em><em>)</em>) – <ul>
<li><p>if value between 0-1 interpreted as fraction of total X to use</p></li>
<li><p>if value &gt; 1, interpreted as the absolute number of random samples of X.</p></li>
</ul>
</p></li>
<li><p><strong>n_bootstrap</strong> (<em>integer</em><em> (</em><em>default=1; no bootstrapping</em><em>)</em>) – Number of bootstrap resamples for computing confidence intervals on the PD curves.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – Partial dependence result dataset</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.DataSet</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">pd</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.perm_based_interaction">
<code class="sig-name descname"><span class="pre">perm_based_interaction</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.perm_based_interaction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.perm_based_interaction" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the performance-based feature interactions from Oh (2019) <a class="footnote-reference brackets" href="#id20" id="id19">6</a>.
For a pair of features, the loss of skill is recorded for permuting
each feature separately and permuting both. If there is no feature interaction
and the covariance between the two features is close to zero, the sum of the
individual losses will approximately equal the loss of skill from permuting
both features. Otherwise, a non-zero difference indicates some interaction.
The differences for different pairs of features can be used to rank the
strength of any feature interactions.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id19">6</a></span></dt>
<dd><p>Oh, Sejong, 2019. Feature Interaction in Terms of Prediction Performance
<a class="reference external" href="https://www.mdpi.com/2076-3417/9/23/5191">https://www.mdpi.com/2076-3417/9/23/5191</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>list of 2-tuple of strings</em>) – Pairs of features to compute the interaction strength for.</p></li>
<li><p><strong>evaluation_fn</strong> (<em>string</em><em> or </em><em>callable</em>) – <p>evaluation/scoring function for evaluating the loss of skill once a feature is permuted.
evaluation_fn can be set to one of the following strings:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;auc&quot;</span></code>, Area under the Curve</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;auprc&quot;</span></code>, Area under the Precision-Recall Curve</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;bss&quot;</span></code>, Brier Skill Score</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mse&quot;</span></code>, Mean Square Error</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;norm_aupdc&quot;</span></code>,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</p></li>
</ul>
</div></blockquote>
<p>Otherwise, evaluation_fn can be any function of form,
<cite>evaluation_fn(targets, predictions)</cite> and must return a scalar value</p>
</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute for.</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1.0 for no subsampling</em><em>)</em>) – <ul>
<li><p>if value is between 0-1, it is interpreted as fraction of total X to use</p></li>
<li><p>if value &gt; 1, interpreted as the absolute number of random samples of X.</p></li>
</ul>
</p></li>
<li><p><strong>n_jobs</strong> (<em>interger</em><em> or </em><em>float</em><em> (</em><em>default=1; no multiprocessing</em><em>)</em>) – <ul>
<li><p>if integer, interpreted as the number of processors to use for multiprocessing</p></li>
<li><p>if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</p></li>
</ul>
</p></li>
<li><p><strong>n_bootstrap</strong> (<em>integer</em><em> (</em><em>default=None for no bootstrapping</em><em>)</em>) – Number of bootstrap resamples for computing confidence intervals on the feature pair rankings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results_ds</strong> – Permutation importance-based feature interaction strength results</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.Dataset</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sfc_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;temp2m&#39;</span><span class="p">,</span> <span class="s1">&#39;sfcT_hrs_bl_frez&#39;</span><span class="p">,</span> <span class="s1">&#39;tmp2m_hrs_bl_frez&#39;</span><span class="p">,</span>
<span class="gp">... </span>     <span class="s1">&#39;uplwav_flux&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars_2d</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="n">important_vars</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_based_interact_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">perm_based_interaction</span><span class="p">(</span>
<span class="gp">... </span>                         <span class="n">important_vars_2d</span><span class="p">,</span> <span class="n">evaluation_fn</span><span class="o">=</span><span class="s1">&#39;norm_aupdc&#39;</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.permutation_importance">
<code class="sig-name descname"><span class="pre">permutation_importance</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">direction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'backward'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.permutation_importance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.permutation_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs single-pass and/or multi-pass permutation importance using a modified version of the
PermutationImportance package (pymint.PermutationImportance) <a class="footnote-reference brackets" href="#id24" id="id21">1</a>. The single-pass approach was first
developed in Brieman (2001) <a class="footnote-reference brackets" href="#id25" id="id22">2</a> and then improved upon in Lakshmanan et al. (2015) <a class="footnote-reference brackets" href="#id26" id="id23">3</a>.</p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The permutation importance rankings can be sensitive to the evaluation function used.
Consider re-computing with multiple evaluation functions.</p>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The permutation importance rankings can be sensitive to the direction used.
Consider re-computing with both forward- and backward-based methods.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Since the permutation importance is a marginal-based method, you can often use
subsample &lt;&lt; 1.0 without substantially altering the feature rankings.
Using a subsample &lt;&lt; 1.0 can reduce the computation time for larger datasets (e.g., &gt;100 K X),
especially since 100-1000s of bootstrap iterations are often required for reliable rankings.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_vars</strong> (<em>integer</em>) – number of variables to calculate the multipass permutation importance for. If <code class="docutils literal notranslate"><span class="pre">n_vars=1</span></code>, then
only the single-pass permutation importance is computed. If <code class="docutils literal notranslate"><span class="pre">n_vars&gt;1</span></code>, both the single-pass
and multiple-pass are computed.</p></li>
<li><p><strong>evaluation_fn</strong> (<em>string</em><em> or </em><em>callable</em>) – <p>evaluation/scoring function for evaluating the loss of skill once a feature is permuted.
evaluation_fn can be set to one of the following strings:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;auc&quot;</span></code>, Area under the Curve</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;auprc&quot;</span></code>, Area under the Precision-Recall Curve</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;bss&quot;</span></code>, Brier Skill Score</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mse&quot;</span></code>, Mean Square Error</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;norm_aupdc&quot;</span></code>,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</p></li>
</ul>
</div></blockquote>
<p>Otherwise, evaluation_fn can be any function of form,
<cite>evaluation_fn(targets, predictions)</cite> and must return a scalar value</p>
<p>When using a custom function, you must also set the scoring strategy (see below).</p>
</p></li>
<li><p><strong>scoring_strategy</strong> (<em>string</em><em> (</em><em>default=None</em><em>)</em>) – <p>This argument is only required if you are using a non-default evaluation_fn (see above)</p>
<p>If the evaluation_fn is positively-oriented (a higher value is better),
then set <code class="docutils literal notranslate"><span class="pre">scoring_strategy</span> <span class="pre">=</span> <span class="pre">&quot;argmin_of_mean&quot;</span></code> and if it is negatively-oriented-
(a lower value is better), then set <code class="docutils literal notranslate"><span class="pre">scoring_strategy</span> <span class="pre">=</span> <span class="pre">&quot;argmax_of_mean&quot;</span></code></p>
</p></li>
<li><p><strong>direction</strong> (<code class="docutils literal notranslate"><span class="pre">&quot;forward&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;backward&quot;</span></code>) – For the multi-pass method. For <code class="docutils literal notranslate"><span class="pre">&quot;backward&quot;</span></code>, the top feature is left permuted before determining
the second-most important feature (and so on). For <code class="docutils literal notranslate"><span class="pre">&quot;forward&quot;</span></code>, all features are permuted
and then the top features are progressively left unpermuted. For real-world datasets, the two
methods often do not produce the same feature rankings and is worth exploring both.</p></li>
<li><p><strong>subsample</strong> (<em>float</em><em> or </em><em>integer</em><em> (</em><em>default=1.0 for no subsampling</em><em>)</em>) – if value is between 0-1, it is interpreted as fraction of total X to use
if value &gt; 1, interpreted as the number of X to randomly sample
from the original dataset.</p></li>
<li><p><strong>n_jobs</strong> (<em>interger</em><em> or </em><em>float</em><em> (</em><em>default=1; no multiprocessing</em><em>)</em>) – if integer, interpreted as the number of processors to use for multiprocessing
if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</p></li>
<li><p><strong>n_bootstrap</strong> (<em>integer</em><em> (</em><em>default=None for no bootstrapping</em><em>)</em>) – Number of bootstrap iterations for computing confidence intervals on the feature rankings.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em>, </em><em>default=None</em>) – Pseudo-random number generator to control the permutations of each
feature. Pass an int to get reproducible results across function calls.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – True for print statements on the progress</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – Permutation importance results. Includes the both multi-pass and single-pass
feature rankings and the scores with the various features permuted.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>xarray.DataSet</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id24"><span class="brackets"><a class="fn-backref" href="#id21">1</a></span></dt>
<dd><p><a class="reference external" href="https://github.com/gelijergensen/PermutationImportance">https://github.com/gelijergensen/PermutationImportance</a></p>
</dd>
<dt class="label" id="id25"><span class="brackets"><a class="fn-backref" href="#id22">2</a></span></dt>
<dd><ol class="upperalpha simple" start="12">
<li><p>Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.</p></li>
</ol>
</dd>
<dt class="label" id="id26"><span class="brackets"><a class="fn-backref" href="#id23">3</a></span></dt>
<dd><p>Lakshmanan, V., C. Karstens, J. Krause, K. Elmore, A. Ryzhkov, and S. Berkseth, 2015:
Which Polarimetric Variables Are Important for Weather/No-Weather Discrimination?
Journal of Atmospheric and Oceanic Technology, 32, 1209–1223,
<a class="reference external" href="https://doi.org/10.1175/jtech-d-13-00205.1">https://doi.org/10.1175/jtech-d-13-00205.1</a>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Only compute for the first model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_imp_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">permutation_importance</span><span class="p">(</span>
<span class="gp">... </span>                      <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="s1">&#39;norm_aupdc&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">perm_imp_results</span><span class="p">)</span>
<span class="go">&lt;xarray.Dataset&gt;</span>
<span class="go">    Dimensions:           (n_bootstrap: 20, n_vars_multipass: 10, n_vars_singlepass: 30)</span>
<span class="go">    Dimensions without coordinates: n_bootstrap, n_vars_multipass, n_vars_singlepass</span>
<span class="go">    Data variables:</span>
<span class="go">        multipass_rankings__Random Forest   (n_vars_multipass) &lt;U17 &#39;sfc_te...</span>
<span class="go">        multipass_scores__Random Forest     (n_vars_multipass, n_bootstrap) float64 ...</span>
<span class="go">        singlepass_rankings__Random Forest  (n_vars_singlepass) &lt;U17 &#39;sfc_t...</span>
<span class="go">        singlepass_scores__Random Forest    (n_vars_singlepass, n_bootstrap) float64 ...</span>
<span class="go">        original_score__Random Forest       (n_bootstrap) float64 0.9851 .....</span>
<span class="go">    Attributes:</span>
<span class="go">        estimator_output:  probability</span>
<span class="go">        estimators used:   [&#39;Random Forest&#39;]</span>
<span class="go">        n_multipass_vars:  10</span>
<span class="go">        method:            permutation_importance</span>
<span class="go">        direction:         backward</span>
<span class="go">        evaluation_fn:     norm_aupdc</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.plot_ale">
<code class="sig-name descname"><span class="pre">plot_ale</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_units</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_probability</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.plot_ale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.plot_ale" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the 1D and 2D accumulated local effects plotting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ale</strong> (<em>xarray.Dataset</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale" title="pymint.main.interpret_toolkit.InterpretToolkit.ale"><code class="xref py py-func docutils literal notranslate"><span class="pre">ale()</span></code></a> for
<code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>features</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>list of 2-tuple of strings</em>) – Features to plot the PD for.  To plot for 2D PD,
pass a list of 2-tuples of features.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em><em> (</em><em>default is None</em><em>)</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to plot for.</p></li>
<li><p><strong>display_feature_names</strong> (<em>dict</em>) – <p>For plotting purposes. Dictionary that maps the feature names
in the pandas.DataFrame to display-friendly versions.
E.g., <code class="docutils literal notranslate"><span class="pre">display_feature_names</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$T_{d}$',</span> <span class="pre">}</span></code></p>
<p>The plotting code can handle latex-style formatting.</p>
</p></li>
<li><p><strong>display_units</strong> (<em>dict</em>) – For plotting purposes. Dictionary that maps the feature names
to their units.
E.g., <code class="docutils literal notranslate"><span class="pre">display_units</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$^\circ$C',</span> <span class="pre">}</span></code></p></li>
<li><p><strong>line_colors</strong> (<em>str</em><em> or </em><em>list of strs of len</em><em>(</em><em>estimators</em><em>)</em>) – User-defined colors for curve plotting.</p></li>
<li><p><strong>to_probability</strong> (<em>boolean</em>) – If True, the values are multipled by 100.</p></li>
<li><p><strong>arguments include arguments typically used for matplotlib.</strong> (<em>Keyword</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fig, axes</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib figure instance and the corresponding axes</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ale</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">ale</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Provide a small subset of features to plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sfc_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;temp2m&#39;</span><span class="p">,</span> <span class="s1">&#39;sfcT_hrs_bl_frez&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;tmp2m_hrs_bl_frez&#39;</span><span class="p">,</span><span class="s1">&#39;uplwav_flux&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_ale</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">important_vars</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/ale_1d.png" src="_images/ale_1d.png" />
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.plot_contributions">
<code class="sig-name descname"><span class="pre">plot_contributions</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrib</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_only_varname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.plot_contributions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.plot_contributions" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots the feature contributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contrib</strong> (<em>Nested pandas.DataFrame</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.local_contributions" title="pymint.main.interpret_toolkit.InterpretToolkit.local_contributions"><code class="xref py py-func docutils literal notranslate"><span class="pre">local_contributions()</span></code></a></p></li>
<li><p><strong>features</strong> (<em>string</em><em> or </em><em>list of strings</em><em> (</em><em>default=None</em><em>)</em>) – Features to plot. If None, all features are eligible to be plotted.
However, the default number of features to plot is 10. Can be set
by n_vars (see keyword arguments).</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em><em> (</em><em>default is None</em><em>)</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to compute the IAS for.</p></li>
<li><p><strong>to_only_varname</strong> (<em>callable</em><em> (</em><em>default=None</em><em>)</em>) – </p></li>
<li><p><strong>display_feature_names</strong> (<em>dict</em>) – For plotting purposes. Dictionary that maps the feature names
in the pandas.DataFrame to display-friendly versions.
E.g., display_feature_names = { ‘dwpt2m’ : ‘T$_{d}$’, }
The plotting code can handle latex-style formatting.</p></li>
<li><p><strong>arguments include arguments typically used for matplotlib</strong> (<em>Keyword</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fig</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib figure instance</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">shap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span> <span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Only give the X you want contributions for.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, we are using a single example.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">single_example</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">single_example</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a background dataset; randomly sample 100 X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">background_dataset</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrib_ds</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">local_contributions</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;shap&#39;</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">background_dataset</span><span class="o">=</span><span class="n">background_dataset</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_contributions</span><span class="p">(</span><span class="n">contrib_ds</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/feature_contribution_single.png" src="_images/feature_contribution_single.png" />
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.plot_importance">
<code class="sig-name descname"><span class="pre">plot_importance</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'multipass'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlabels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_used</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_correlated_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.plot_importance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.plot_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>Method for plotting the permutation importance and other ranking-based results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<em>'multipass'</em><em>, </em><em>'singlepass'</em><em>, </em><em>'perm_based'</em><em>, </em><em>'ale_variance'</em><em>, or </em><em>'ale_variance_interactions'</em>) – Method used to compute the feature rankings.</p></li>
<li><p><strong>data</strong> (<em>xarray.Dataset</em><em> or </em><em>list of xarray.Datasets</em>) – <p>Results from</p>
<ul>
<li><p><a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.permutation_importance" title="pymint.main.interpret_toolkit.InterpretToolkit.permutation_importance"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation_importance()</span></code></a></p></li>
<li><p><a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.ale_variance" title="pymint.main.interpret_toolkit.InterpretToolkit.ale_variance"><code class="xref py py-func docutils literal notranslate"><span class="pre">ale_variance()</span></code></a></p></li>
<li><p><a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.friedman_h_stat" title="pymint.main.interpret_toolkit.InterpretToolkit.friedman_h_stat"><code class="xref py py-func docutils literal notranslate"><span class="pre">friedman_h_stat()</span></code></a></p></li>
<li><p><a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.perm_based_interaction" title="pymint.main.interpret_toolkit.InterpretToolkit.perm_based_interaction"><code class="xref py py-func docutils literal notranslate"><span class="pre">perm_based_interaction()</span></code></a></p></li>
</ul>
</p></li>
<li><p><strong>xlabels</strong> (<em>list of strings</em>) – X-axis label</p></li>
<li><p><strong>ylabels</strong> (<em>list of strings</em>) – Y-axis label or multiple labels for each row in a multi-panel plot.</p></li>
<li><p><strong>metrics_used</strong> (<em>list of strings</em>) – Determined internally if possible.</p></li>
<li><p><strong>plot_correlated_features</strong> (<em>boolean</em>) – If True, pairs of features with a linear correlation coefficient &gt; 0.8
are annotate/paired by bars or color-coding. This is useful for identifying
spurious rankings due to the correlations.</p></li>
<li><p><strong>kwargs</strong> (<em>keyword arguments</em>) – </p></li>
<li><p><strong>num_vars_to_plot</strong> (<em>integer</em>) – Number of features to plot from permutation importance calculation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fig</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib figure instance</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_imp_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">permutation_importance</span><span class="p">(</span>
<span class="gp">... </span>                      <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="s1">&#39;norm_aupdc&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">direction</span> <span class="o">=</span> <span class="s1">&#39;backward&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">perm_imp_results</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;multipass&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">#If we want to annonate pairs of highly correlated feature pairs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">perm_imp_results</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;multipass&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">plot_correlated_features</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/multi_pass_perm_imp.png" src="_images/multi_pass_perm_imp.png" />
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.plot_pd">
<code class="sig-name descname"><span class="pre">plot_pd</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimator_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_units</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_colors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_probability</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.plot_pd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.plot_pd" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the 1D and 2D partial dependence plotting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pd</strong> (<em>xarray.Dataset</em>) – Results of <a class="reference internal" href="#pymint.main.interpret_toolkit.InterpretToolkit.pd" title="pymint.main.interpret_toolkit.InterpretToolkit.pd"><code class="xref py py-func docutils literal notranslate"><span class="pre">pd()</span></code></a> for
<code class="docutils literal notranslate"><span class="pre">features</span></code>.</p></li>
<li><p><strong>features</strong> (<em>string</em><em>, </em><em>list of strings</em><em>, </em><em>list of 2-tuple of strings</em>) – Features to plot the PD for.  To plot for 2D PD,
pass a list of 2-tuples of features.</p></li>
<li><p><strong>estimator_names</strong> (<em>string</em><em>, </em><em>list of strings</em><em> (</em><em>default is None</em><em>)</em>) – If using multiple estimators, you can pass a single (or subset of) estimator name(s)
to plot for.</p></li>
<li><p><strong>display_feature_names</strong> (<em>dict</em>) – <p>For plotting purposes. Dictionary that maps the feature names
in the pandas.DataFrame to display-friendly versions.
E.g., <code class="docutils literal notranslate"><span class="pre">display_feature_names</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$T_{d}$',</span> <span class="pre">}</span></code></p>
<p>The plotting code can handle latex-style formatting.</p>
</p></li>
<li><p><strong>display_units</strong> (<em>dict</em>) – For plotting purposes. Dictionary that maps the feature names
to their units.
E.g., <code class="docutils literal notranslate"><span class="pre">display_units</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$^\circ$C',</span> <span class="pre">}</span></code></p></li>
<li><p><strong>line_colors</strong> (<em>str</em><em> or </em><em>list of strs of len</em><em>(</em><em>estimators</em><em>)</em>) – User-defined colors for curve plotting.</p></li>
<li><p><strong>to_probability</strong> (<em>boolean</em>) – If True, the values are multipled by 100.</p></li>
<li><p><strong>arguments include arguments typically used for matplotlib.</strong> (<em>Keyword</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fig, axes</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib figure instance and the corresponding axes</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span> <span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">calc_pd</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Provide a small subset of features to plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sfc_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;temp2m&#39;</span><span class="p">,</span> <span class="s1">&#39;sfcT_hrs_bl_frez&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s1">&#39;tmp2m_hrs_bl_frez&#39;</span><span class="p">,</span><span class="s1">&#39;uplwav_flux&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_pd</span><span class="p">(</span><span class="n">pd</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">important_vars</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.plot_shap">
<code class="sig-name descname"><span class="pre">plot_shap</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">plot_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'summary'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shap_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_units</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.plot_shap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.plot_shap" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the SHapley Additive Explanations (SHAP) <a class="footnote-reference brackets" href="#id33" id="id27">13</a> <a class="footnote-reference brackets" href="#id34" id="id28">14</a> <a class="footnote-reference brackets" href="#id35" id="id29">15</a> summary plot or dependence
plots for various features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>plot_type</strong> (<code class="docutils literal notranslate"><span class="pre">'summary'</span></code> or <code class="docutils literal notranslate"><span class="pre">'dependence'</span></code>) – if ‘summary’, plots a feature importance-style plot
if ‘dependence’, plots a partial depedence style plot</p></li>
<li><p><strong>shap_values</strong> (<em>array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – SHAP values</p></li>
<li><p><strong>features</strong> (<em>string</em><em> or </em><em>list of strings</em><em> (</em><em>default=None</em><em>)</em>) – features to plots if plot_type is ‘dependence’.</p></li>
<li><p><strong>display_feature_names</strong> (<em>dict</em>) – For plotting purposes. Dictionary that maps the feature names
in the pandas.DataFrame to display-friendly versions.
E.g., <code class="docutils literal notranslate"><span class="pre">display_feature_names</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$T_{d}$',</span> <span class="pre">}</span></code>
The plotting code can handle latex-style formatting.</p></li>
<li><p><strong>display_units</strong> (<em>dict</em>) – For plotting purposes. Dictionary that maps the feature names
to their units.
E.g., <code class="docutils literal notranslate"><span class="pre">display_units</span> <span class="pre">=</span> <span class="pre">{</span> <span class="pre">'dwpt2m'</span> <span class="pre">:</span> <span class="pre">'$^\circ$C',</span> <span class="pre">}</span></code></p></li>
<li><p><strong>to_probability</strong> (<em>boolean</em>) – if True, values are multiplied by 100.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fig</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib figure instance</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">shap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a background dataset; randomly sample 100 X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">background_dataset</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shap_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap</span><span class="p">(</span><span class="n">background_dataset</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">)</span>
<span class="gp">... </span><span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shap_values</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">shap_results</span><span class="p">[</span><span class="n">estimator_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Plot the SHAP-summary style plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_shap</span><span class="p">(</span><span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;summary&#39;</span><span class="p">,</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Plot the SHAP-dependence style plot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sfc_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;temp2m&#39;</span><span class="p">,</span> <span class="s1">&#39;sfcT_hrs_bl_frez&#39;</span><span class="p">,</span> <span class="s1">&#39;tmp2m_hrs_bl_frez&#39;</span><span class="p">,</span><span class="s1">&#39;uplwav_flux&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">plot_shap</span><span class="p">(</span><span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;dependence&#39;</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">important_vars</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/shap_dependence.png" src="_images/shap_dependence.png" />
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save results of a computation (permutation importance, calc_ale, calc_pd, etc)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fname</strong> (<em>string</em>) – filename to store the results in (including path)</p></li>
<li><p><strong>data</strong> (<em>InterpretToolkit results</em>) – the results of a InterpretToolkit calculation. Can be a dataframe or dataset.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span> <span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm_imp_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">calc_permutation_importance</span><span class="p">(</span>
<span class="gp">... </span>                      <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="s1">&#39;norm_aupdc&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">direction</span> <span class="o">=</span> <span class="s1">&#39;backward&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;path/to/save/the/file&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">perm_imp_results</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="pymint.main.interpret_toolkit.InterpretToolkit.shap">
<code class="sig-name descname"><span class="pre">shap</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">background_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pymint/main/interpret_toolkit.html#InterpretToolkit.shap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pymint.main.interpret_toolkit.InterpretToolkit.shap" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the SHapley Additive Explanations (SHAP) values <a class="footnote-reference brackets" href="#id33" id="id30">13</a> <a class="footnote-reference brackets" href="#id34" id="id31">14</a> <a class="footnote-reference brackets" href="#id35" id="id32">15</a>. The calculations starts
with the Tree-based explainer and then defaults to the Kernel-based explainer for
non-tree based estimators. If using a non-tree based estimators, then you must provide a
background dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>background_dataset</strong> (<em>array of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – A representative (often a K-means or random sample) subset of the
data used to train the ML estimator. Used for the background dataset
to compute the expected values for the SHAP calculations.
Only required for non-tree based methods.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>results</strong> – Dictionary where the keys represent estimator names, and the
values represent a tuple of SHAP values and the bias.
shap_values is of type numpy.array (n_samples, n_features)
bias is of type numpy.array (1, n_features)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id33"><span class="brackets">13</span><span class="fn-backref">(<a href="#id27">1</a>,<a href="#id30">2</a>)</span></dt>
<dd><p><a class="reference external" href="https://christophm.github.io/interpretable-ml-book/shap.html">https://christophm.github.io/interpretable-ml-book/shap.html</a></p>
</dd>
<dt class="label" id="id34"><span class="brackets">14</span><span class="fn-backref">(<a href="#id28">1</a>,<a href="#id31">2</a>)</span></dt>
<dd><p>Lundberg, S. M., G. G. Erion, and S.-I. Lee, 2018: Consistent Individualized
Feature Attribution for Tree Ensembles. Arxiv,.</p>
</dd>
<dt class="label" id="id35"><span class="brackets">15</span><span class="fn-backref">(<a href="#id29">1</a>,<a href="#id32">2</a>)</span></dt>
<dd><p>Lundberg, S. M., and Coauthors, 2020: From local explanations to global understanding
with explainable AI for trees. Nat Mach Intell, 2, 56–67, <a class="reference external" href="https://doi.org/10.1038/s42256-019-0138-9">https://doi.org/10.1038/s42256-019-0138-9</a>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">shap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pre-fit estimators within pymint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator_objs</span><span class="p">,</span> <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span> <span class="c1"># training data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">pymint</span><span class="o">.</span><span class="n">InterpretToolkit</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimator_objs</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a background dataset; randomly sample 100 X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">background_dataset</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shap_results</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap</span><span class="p">(</span><span class="n">background_dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<div class="toctree-wrapper compound">
</div>
<section id="contribute">
<h2>Contribute<a class="headerlink" href="#contribute" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Issue Tracker: github.com/monte-flora/py-mint/issues</p></li>
<li><p>Source Code: github.com/monte-flora/py-mint</p></li>
</ul>
</section>
<section id="support">
<h2>Support<a class="headerlink" href="#support" title="Permalink to this headline">¶</a></h2>
<p>If you are having issues, please let us know.
We have a mailing list located at: <a class="reference external" href="mailto:monte&#46;flora&#37;&#52;&#48;noaa&#46;gov">monte<span>&#46;</span>flora<span>&#64;</span>noaa<span>&#46;</span>gov</a></p>
</section>
<section id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<p>The project is licensed under the BSD license.</p>
</section>
<section id="indices-and-tables">
<h2>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div>
      
      
      
      
      
      
      
        <ul>
          <li><a href="http://data.pp.audeering.com">Data</a></li>
          <li><a href="http://devops.pp.audeering.com/sphinx/">Documentation</a></li>
          <li><a href="http://devops.pp.audeering.com">Infrastructure</a></li>
          <li><a href="http://models.pp.audeering.com">Models</a></li>
          <li><a href="http://devops.pp.audeering.com/python/">Python</a></li>
          <li><a href="http://tools.pp.audeering.com">Tools</a></li>
        </ul>
      
    <p>
        
        
        
          Built with <a href="https://www.sphinx-doc.org/en/master/">Sphinx</a> on 2021/04/10 using the <a href="https://github.com/audeering/sphinx-audeering-theme/">audEERING theme</a>
        
    </p>
  </div>

  <div role="contentinfo">
    <p>
        
      &copy; 2021, Montgomery Flora; Shawn Handler
    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  



  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>